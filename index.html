<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description"
    content="FRAME: Feature Representation and Anticipation with Memory - A self-supervised video frame encoder for dense video understanding">
  <meta property="og:title" content="FRAME: Feature Representation and Anticipation with Memory" />
  <meta property="og:description"
    content="A self-supervised video frame encoder that learns temporally consistent, spatially dense features for dense video prediction tasks" />
  <meta property="og:url" content="" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/FRAME_teaser.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />

  <meta name="twitter:title" content="FRAME: Feature Representation and Anticipation with Memory">
  <meta name="twitter:description" content="A self-supervised video frame encoder for dense video understanding">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/FRAME_teaser.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords"
    content="computer vision, video understanding, self-supervised learning, dense prediction, video segmentation">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>FRAME: Feature Representation and Anticipation with Memory</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  
  <style>
    /* Custom animations and styles */
    @keyframes fadeInUp {
      from {
        opacity: 0;
        transform: translateY(30px);
      }
      to {
        opacity: 1;
        transform: translateY(0);
      }
    }
    
    @keyframes slideInLeft {
      from {
        opacity: 0;
        transform: translateX(-50px);
      }
      to {
        opacity: 1;
        transform: translateX(0);
      }
    }
    
    @keyframes slideInRight {
      from {
        opacity: 0;
        transform: translateX(50px);
      }
      to {
        opacity: 1;
        transform: translateX(0);
      }
    }
    
    @keyframes scaleIn {
      from {
        opacity: 0;
        transform: scale(0.8);
      }
      to {
        opacity: 1;
        transform: scale(1);
      }
    }
    
    .fade-in-up {
      animation: fadeInUp 0.8s ease-out;
    }
    
    .slide-in-left {
      animation: slideInLeft 0.8s ease-out;
    }
    
    .slide-in-right {
      animation: slideInRight 0.8s ease-out;
    }
    
    .scale-in {
      animation: scaleIn 0.6s ease-out;
    }
    
    .hero-body {
      animation: fadeInUp 1s ease-out;
    }
    
    .publication-title {
      animation: fadeInUp 1.2s ease-out;
    }
    
    .publication-authors {
      animation: fadeInUp 1.4s ease-out;
    }
    
    .publication-links {
      animation: fadeInUp 1.6s ease-out;
    }
    
    /* Hover effects */
    .external-link:hover {
      transform: translateY(-2px);
      transition: transform 0.3s ease;
    }
    
    .table tr:hover {
      transform: scale(1.02);
      transition: transform 0.2s ease;
    }
    
    /* Video hover effects */
    video:hover {
      transform: scale(1.05);
      transition: transform 0.3s ease;
      box-shadow: 0 10px 30px rgba(0,0,0,0.3);
    }
    
    /* Image hover effects */
    img:hover {
      transform: scale(1.02);
      transition: transform 0.3s ease;
    }
    
    /* Floating animation for teaser */
    .teaser-float {
      animation: float 6s ease-in-out infinite;
    }
    
    @keyframes float {
      0%, 100% { transform: translateY(0px); }
      50% { transform: translateY(-10px); }
    }
    
    /* Gradient backgrounds */
    .hero.is-light {
      background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
    }
    
    .section.hero {
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      color: white;
    }
    
    .section.hero .title {
      color: white;
    }
    
    /* Staggered animations for tables */
    .table tbody tr {
      animation: fadeInUp 0.6s ease-out;
    }
    
    .table tbody tr:nth-child(1) { animation-delay: 0.1s; }
    .table tbody tr:nth-child(2) { animation-delay: 0.2s; }
    .table tbody tr:nth-child(3) { animation-delay: 0.3s; }
    .table tbody tr:nth-child(4) { animation-delay: 0.4s; }
    .table tbody tr:nth-child(5) { animation-delay: 0.5s; }
    .table tbody tr:nth-child(6) { animation-delay: 0.6s; }
    
    /* Pulse animation for highlighted rows */
    .has-background-success-light {
      animation: pulse 2s ease-in-out infinite alternate;
    }
    
    @keyframes pulse {
      0% { background-color: #d4edda; }
      100% { background-color: #c3e6cb; }
    }
  </style>
</head>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">FRAME: Feature Representation and Anticipation with Memory</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="mailto:st34@illinois.edu" target="_blank">Sethuraman T V</a><sup>1,2</sup>,</span>
              <span class="author-block">
                <a href="https://savya08.github.io/" target="_blank">Savya Khosla</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="https://trevahok.github.io" target="_blank">Vignesh Srinivasakumar</a><sup>2†</sup>,</span>
              <span class="author-block">
                <a href="https://gabriel-huang.github.io/" target="_blank">Jiahui Huang</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://sites.google.com/view/seoungwugoh/" target="_blank">Seoung Wug Oh</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://sjenni.github.io/" target="_blank">Simon Jenni</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://dhoiem.cs.illinois.edu/" target="_blank">Derek Hoiem</a><sup>2*</sup>,</span>
              <span class="author-block">
                <a href="https://joonyoung-cv.github.io/" target="_blank">Joon-Young Lee</a><sup>1*</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <span style="color: #FF0000;">Adobe Research</span><sup>1</sup>,
                <span style="color: #13294B;">University of Illinois Urbana-Champaign</span><sup>2</sup><br>
              </span>
              <span class="eql-cntrb">
                <small><br><sup>*</sup>Equal advising, <sup>†</sup>Now at <span
                    style="color: #76B900;">NVIDIA</span></small>
              </span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="neurips_2025.pdf" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>

                <!-- Supplementary PDF link -->
                <span class="link-block">
                  <a href="23370_FRAME_Pre_Training_Video_Supplementary Material.zip" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Supplementary</span>
                  </a>
                </span>

                <!-- Github link -->
                <span class="link-block">
                  <a href="#" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (Coming Soon)</span>
                  </a>
                </span>

              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Teaser image -->
  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <div class="scale-in">
          <img src="figures/image.png" alt="FRAME Teaser" class="center teaser-float">
        </div>
        <h2 class="subtitle has-text-centered fade-in-up">
          FRAME outperforms state-of-the-art self-supervised models (DINO, SiamMAE) on multiple dense video tasks. The
          student (FRAME) surpasses the teacher (DINO) by learning to predict current and future features using memory,
          improving temporal consistency and visual correspondence. (Right) Eg: VOS where FRAME improves segmentation of
          horse and rider. (left) Tasks shown: VOS = Video Object Segmentation, Part Prop. = Part Propagation, Pose
          Prop. = Pose Propagation, Seg = Semantic Segmentation of current & future frame.
        </h2>
      </div>
    </div>
  </section>


  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3 fade-in-up">Abstract</h2>
          <div class="content has-text-justified slide-in-left">
            <p>
              Dense video prediction tasks, such as object tracking and semantic segmentation, require video encoders
              that generate temporally consistent, spatially dense features for every frame. However, existing
              approaches fall short: image encoders like DINO or CLIP lack temporal awareness, while video models such
              as VideoMAE underperform compared to image encoders on dense prediction tasks. We address this gap with
              <strong>FRAME</strong>, a self-supervised video frame encoder tailored for dense video understanding.
              FRAME learns to predict current and future DINO patch features from past and present RGB frames, leading
              to spatially precise and temporally coherent representations. To our knowledge, FRAME is the first video
              encoder to leverage image-based models for dense prediction while outperforming them on tasks requiring
              fine-grained visual correspondence. As an auxiliary capability, FRAME aligns its class token with CLIP's
              semantic space, supporting language-driven tasks such as video classification. We evaluate FRAME across
              <em>six dense prediction tasks</em> on <em>seven datasets</em>, where it consistently outperforms image
              encoders and existing self-supervised video models. Despite its versatility, FRAME maintains a compact
              architecture suitable for a range of downstream applications.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->

  <!-- Method Overview -->
  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3 fade-in-up">Method Overview</h2>
          <div class="content has-text-justified slide-in-right">
            <p>
              FRAME is trained in two stages. In Stage 1, we train a student encoder to match dense patch-level and
              class-level features from frozen image-based teacher models (DINO and CLIP). In Stage 2, we equip the
              student with lightweight temporal modules—a memory unit that aggregates past context and an anticipation
              unit that predicts future features.
            </p>
          </div>
          <div class="scale-in">
            <img src="figures/framework.png" alt="FRAME Framework" class="center">
          </div>
          <h2 class="subtitle has-text-centered fade-in-up">
            Overview of FRAME Architecture and Two-Stage Training Process. 
          </h2>
        </div>
      </div>
    </div>
  </section>

  <!-- Video carousel - Now placed before downstream tasks -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3 has-text-centered fade-in-up">Video Examples</h2>
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-video1 has-text-centered scale-in">
            <video poster="" id="video1" autoplay controls muted loop class="is-centered">
              <source src="static/videos/demo1.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-video2 has-text-centered scale-in">
            <video poster="" id="video2" autoplay controls muted loop class="is-centered">
              <source src="static/videos/demo2.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End video carousel -->

  <!-- Downstream Tasks (previously Key Results) - Reduced size -->
  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3 has-text-centered fade-in-up">Downstream Tasks</h2>
        <div id="downstream-carousel" class="carousel results-carousel">
          <div class="item slide-in-left">
            <!-- Your image here -->
            <img src="figures/Figure_1.png" alt="Video Object Segmentation Results" style="max-height: 300px; object-fit: contain;" />
            <h2 class="subtitle has-text-centered" style="font-size: 1rem; margin-top: 0.5rem;">
              Video Object Segmentation on DAVIS
            </h2>
          </div>
          <div class="item slide-in-right">
            <!-- Your image here -->
            <img src="figures/Figure_2.png" alt="Semantic Part Propagation Results" style="max-height: 300px; object-fit: contain;" />
            <h2 class="subtitle has-text-centered" style="font-size: 1rem; margin-top: 0.5rem;">
              Semantic Part Propagation on VIP
            </h2>
          </div>
          <div class="item slide-in-left">
            <!-- Your image here -->
            <img src="figures/Figure_3.png" alt="Pose Propagation Results" style="max-height: 300px; object-fit: contain;" />
            <h2 class="subtitle has-text-centered" style="font-size: 1rem; margin-top: 0.5rem;">
              Pose Propagation on JHMDB
            </h2>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End downstream tasks -->

  <!-- Main Results Table -->
  <section class="section hero">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3 fade-in-up">Performance Comparison</h2>
          <div class="content scale-in">
            <p>FRAME substantially outperforms existing self-supervised methods on visual correspondence tasks:</p>

            <table class="table is-bordered is-striped is-narrow is-hoverable">
              <thead>
                <tr>
                  <th>Method</th>
                  <th>Backbone</th>
                  <th>DAVIS (J&F)</th>
                  <th>VIP (mIoU)</th>
                  <th>JHMDB (PCK@0.1)</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>DINO</td>
                  <td>ViT-S/16</td>
                  <td>61.8</td>
                  <td>36.2</td>
                  <td>45.6</td>
                </tr>
                <tr>
                  <td>SiamMAE</td>
                  <td>ViT-S/16</td>
                  <td>62.0</td>
                  <td>37.3</td>
                  <td>47.0</td>
                </tr>
                <tr class="has-background-success-light">
                  <td><strong>FRAME (ours)</strong></td>
                  <td><strong>ViT-S/16</strong></td>
                  <td><strong>65.7</strong></td>
                  <td><strong>41.2</strong></td>
                  <td><strong>48.7</strong></td>
                </tr>
                <tr>
                  <td>DINO</td>
                  <td>ViT-S/8</td>
                  <td>69.9</td>
                  <td>39.5</td>
                  <td>56.5</td>
                </tr>
                <tr>
                  <td>SiamMAE</td>
                  <td>ViT-S/8</td>
                  <td>71.4</td>
                  <td>45.9</td>
                  <td>61.9</td>
                </tr>
                <tr class="has-background-success-light">
                  <td><strong>FRAME (ours)</strong></td>
                  <td><strong>ViT-S/8</strong></td>
                  <td><strong>73.2</strong></td>
                  <td><strong>47.9</strong></td>
                  <td><strong>64.1</strong></td>
                </tr>
              </tbody>
            </table>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Qualitative Results -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3 fade-in-up">Qualitative Examples</h2>
          <div class="scale-in">
            <img src="figures/FRAME_teaser.png" alt="FRAME vs DINO Qualitative Results" style="width: 100%;">
          </div>
          <h2 class="subtitle has-text-centered slide-in-right">
            Comparison of FRAME and DINO on feature propagation across video frames. FRAME demonstrates greater
            robustness to viewpoint changes, occlusions, and object reappearances, making it a more suitable video frame
            encoder.
          </h2>
        </div>
      </div>
    </div>
  </section>

  <!-- DINO vs FRAME Comparison -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3 has-text-centered fade-in-up">DINO (Left) vs FRAME (Right) - Comparison</h2>
        <div id="dino-frame-carousel" class="carousel results-carousel">
          <div class="item item-video1 has-text-centered scale-in">
            <video poster="" id="dino-frame1" autoplay controls muted loop class="is-centered">
              <source src="static/videos/dino_vs_frame/0_html5.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-video2 has-text-centered scale-in">
            <video poster="" id="dino-frame2" autoplay controls muted loop class="is-centered">
              <source src="static/videos/dino_vs_frame/2_html5.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-video3 has-text-centered scale-in">
            <video poster="" id="dino-frame3" autoplay controls muted loop class="is-centered">
              <source src="static/videos/dino_vs_frame/11_html5.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-video4 has-text-centered scale-in">
            <video poster="" id="dino-frame4" autoplay controls muted loop class="is-centered">
              <source src="static/videos/dino_vs_frame/12_html5.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-video5 has-text-centered scale-in">
            <video poster="" id="dino-frame5" autoplay controls muted loop class="is-centered">
              <source src="static/videos/dino_vs_frame/15_html5.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-video6 has-text-centered scale-in">
            <video poster="" id="dino-frame6" autoplay controls muted loop class="is-centered">
              <source src="static/videos/dino_vs_frame/16_html5.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-video7 has-text-centered scale-in">
            <video poster="" id="dino-frame7" autoplay controls muted loop class="is-centered">
              <source src="static/videos/dino_vs_frame/19_html5.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-video8 has-text-centered scale-in">
            <video poster="" id="dino-frame8" autoplay controls muted loop class="is-centered">
              <source src="static/videos/dino_vs_frame/21_html5.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-video9 has-text-centered scale-in">
            <video poster="" id="dino-frame9" autoplay controls muted loop class="is-centered">
              <source src="static/videos/dino_vs_frame/29_html5.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End DINO vs FRAME Comparison -->

  <!-- Ablation Studies -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3 fade-in-up">Insights</h2>
          <div class="content">
            <div class="scale-in">
              <table class="table is-bordered is-striped is-narrow is-hoverable">
                <thead>
                  <tr>
                    <th>Memory</th>
                    <th>Anticipation</th>
                    <th>Stages</th>
                    <th>Data</th>
                    <th>DAVIS (J&F)</th>
                    <th>VIP (mIoU)</th>
                    <th>JHMDB (PCK)</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>✗</td>
                    <td>✗</td>
                    <td>Stage 1</td>
                    <td>Kinetics</td>
                    <td>62.1</td>
                    <td>39.0</td>
                    <td>46.6</td>
                  </tr>
                  <tr>
                    <td>✓</td>
                    <td>✓</td>
                    <td>2-Stage</td>
                    <td>Kinetics</td>
                    <td>65.7</td>
                    <td>41.2</td>
                    <td>48.7</td>
                  </tr>
                  <tr>
                    <td>✓</td>
                    <td>✗</td>
                    <td>2-Stage</td>
                    <td>Kin.+Ego4D</td>
                    <td>65.5</td>
                    <td>41.2</td>
                    <td>48.6</td>
                  </tr>
                  <tr class="has-background-success-light">
                    <td><strong>✓</strong></td>
                    <td><strong>✓</strong></td>
                    <td><strong>2-Stage</strong></td>
                    <td><strong>Kin.+Ego4D</strong></td>
                    <td><strong>66.3</strong></td>
                    <td><strong>42.0</strong></td>
                    <td><strong>49.0</strong></td>
                  </tr>
                </tbody>
              </table>
            </div>

            <p class="slide-in-left">Both memory and anticipation components contribute significantly to performance, with the two-stage
              training providing the best results.</p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Semantic Segmentation Results -->
  <section class="section hero">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3 fade-in-up">Semantic Segmentation and Anticipation</h2>
          <div class="content">
            <div class="columns">
              <div class="column is-7 slide-in-left">
                <img src="figures/step_anticipation.png" alt="Semantic segmentation on current and future frames" class="center">
                <p class="has-text-centered"><strong>Semantic segmentation on current and future frames.</strong></p>
              </div>
              <div class="column is-5 slide-in-right">
                <table class="table is-bordered is-striped is-narrow">
                  <thead>
                    <tr>
                      <th>Model</th>
                      <th>CamVid Current</th>
                      <th>CamVid Future</th>
                      <th>VSPW Current</th>
                      <th>VSPW Future</th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td>DINO ViT-S/16</td>
                      <td>60.1</td>
                      <td>50.2</td>
                      <td>36.4</td>
                      <td>25.6</td>
                    </tr>
                    <tr class="has-background-success-light">
                      <td><strong>FRAME ViT-S/8</strong></td>
                      <td><strong>62.6</strong></td>
                      <td><strong>54.0</strong></td>
                      <td><strong>38.0</strong></td>
                      <td><strong>27.4</strong></td>
                    </tr>
                    <tr>
                      <td>DINOv2 ViT-L/14</td>
                      <td>68.3</td>
                      <td>56.1</td>
                      <td>41.8</td>
                      <td>30.3</td>
                    </tr>
                    <tr class="has-background-success-light">
                      <td><strong>FRAME ViT-L/14</strong></td>
                      <td><strong>69.8</strong></td>
                      <td><strong>59.2</strong></td>
                      <td><strong>44.0</strong></td>
                      <td><strong>33.8</strong></td>
                    </tr>
                  </tbody>
                </table>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Comparison of Performance vs Parameters -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3 fade-in-up">Performance vs Parameters</h2>
          <div class="content">
            <div class="scale-in">
              <img src="figures/performance_chart_1.png" alt="FRAME outperforms DINO with fewer parameters." class="center">
            </div>
            <p class="has-text-centered slide-in-left"><strong>FRAME outperforms DINO with fewer parameters.</strong></p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!--BibTex citation -->
  <!-- <section class="section" id="BibTeX">
    <div class="container is-max-desktop content is-dark">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{frame2025,
  title={FRAME: Feature Representation and Anticipation with Memory},
  author={Anonymous Authors},
  journal={Neural Information Processing Systems},
  year={2025}
}</code></pre>
    </div>
  </section> -->
  <!--End BibTex citation -->

</body>



<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

</html>
